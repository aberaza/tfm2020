\documentclass[../tfm.tex]{subfiles}

\begin{document}

Históricamente, los modelos de predicción de caídas están íntimamente ligados al estudio del reconocimiento de actividades humanas (\textit{HAR} del inglés \textit{Human Activity Recognition}): discernir a partir de los datos de los sensores qué acción (\textit{AVC} por \textit{Actividad Vida Cotidiana}, o \textit{ADL} por sus siglas en inglés) estaba realizando el individuo. Según \cite[p.10692]{Ozdemir2014} una caída o golpe no es más que otra actividad y deben considerarse una parte de este problema ya que "son eventos que suceden de forma involuntaria e inesperada durante la realización de las mismas".


\section{Detección de actividad humana y caídas}\label{sect:sa_har}

En \cite[p.2]{Anita2020} se recopilan y definen los principios básicos que debería cumplir un buen sistema de deteción de caídas y que replicamos a continuación:

\begin{itemize}
  \item No ser obtrusivos
  \item No restringir la mobilidad del sujeto
  \item Tener baja latencia
  \item Ser capaz de diferenciar caídas de otras actividades humanas
\end{itemize}

En \cite{Musci2020,Anita2020}, se introducen varias clasificaciones de estos sistemas. En el contexto del presente trabajo, resultan de especial interés la rama de los sistemas \textit{llevables}: "Aquellos en los que los sensores usados para la detección se encuentran embebidos en un dispositivo que debe llevar pueto el sujeto, como por ejemplo en una pulsera" \cite[p.3]{Anita2020}. A su vez podemos dividir estos según el tipo de modelo utilizado para analizar los datos \cite{Anita2020,Lim2014}, en "dos acercamientos principales, los basados en cotas o límites y los basados en aprendizaje automático"\cite[p.1]{Lim2014}


\subsection{Modelos Analíticos: cálculos basados en cotas}\label{sa_modelos_analiticos}

Los primeros acercamientos (\cite{fallindex00, Kangas2008}) al problema de la detección de caídas utilizaron modelos matemáticos basados en el análisis de diferentes parámetros físicos como la aceleración vertical, módulo de la aceleración y postura. Como observa \cite{Bagala2012}, estos métodos puedan conseguir buenos resultados aplicados a pruebas de laboratorio o experimentos controlados, pero no en experimentos de uso real. En parte por un sobreajuste de la calibración de los valores al experimento. En general estos métodos contraponen sensibilidad a especificidad o a la inversa, como puede deducirse de los resultados de \cite{Chen2005,Bourke2006,Kangas2008,Vilarinho2015} y verifica \cite{Anita2020}. A pesar de ello, estos métodos siguen siendo ampliamente utilizados hoy en día por la baja complejidad computacional que requieren, lo que permite ser integrados en pequeños dispositivos poco obtrusivos y con bajas latencias, cumpliendo tres de los cuatro requisitos antes mencionados.


Sobre cálculos basados en cotas, tenemos \cite{fallindex00}, Kangas\cite{Kangas2008} lo compara con el uso ya sea de aceleración vertical o modulo de la aceleración y de nuevo obtiene resultados dispares según el tipo de caída simulada.

La posición de los sensores es también importante, como recalcan \cite{Bagala2012, Vilarinho2015}. Ambos usan smartphones o pulseras de actividad en diferentes posiciones para la captura de la aceleración con resultados muy dispares según el tipo de caída o el tipo de experimento. En el caso de \cite{Vilarinho2015} a pesar de introducir las pulseras como instrumento de captura, delega en un equipo externo (en su caso un teléfono) el análisis y detección de caídas, de manera similar a los experimentos conducidos por \cite{Luque2014} quien añade la posibilidad de realizar el cómputo en un servidor conectado a internet.

\info{REFERENCIA PERDIDA:
Luque2014??
Realmente el monitorizado básico no está tan lejos del resto de métodos e incluso son mejores que algunas implementaciones propietarias comerciales.
Recalca: alta variabilidad de los resultados segúl el tipo de caída (están demasiado optimizados para un tipo concreto, no son de uso general), también hace hincapié en los problemas de usabilidad por parte de usuarios no expertos.}

\todohide{
1- Monitorizado básico (usar módulo del vector aceleración y un threshold X )
2- Fall Index (Yoshida,  T.;  Mizuno,  F.;  Hayasaka,  T.;  Tsubota,  K.;  Wada,  S.;  Yamaguchi,  T.  A  Wearable  Computer System for a Detection and Prevention of Elderly Users from Falling. In Proceedings of  the  12th  International  Conference  on  Biomedical  and  Medical  Engineering  (ICBME),  Singapore, Singapore, 7–10 December 2005.  )
3- PerFallD (Dai, J.; Bai, X.; Yang, Z.; Shen, Z.; Xuan, D. PerFallD: A Pervasive Fall Detection System using Mobile   Phones.   In   Proceedings   of   the   8th   IEEE   International   Conference   on   Pervasive   Computing  and  Communications  Workshops  (PERCOM  Workshops),  Mannheim,  Germany,    29 March–2 April 2010; pp. 292–297) (usa también un giroscopio)
4- iFall (Sposaro,  F.;  Tyson,  G.  IFall:  An  Android  Application  for  Fall  Monitoring  and  Response.    In Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC 2009), Minneapolis, MN, USA, 2–6 September 2009; pp. 6119–6122. )}




\subsection{Modelos de Aprendizaje Automático}\label{sa_modelos_ml}

La segunda gran familia de modelos utiliza técnicas como K-Nearest Neighbours, LSM (\textit{Least Square Method} o \textit{Método de Mínimos Cuadrados}), SVM, Detección Bayesiana, DTW y Redes Neuronales aplicadas a la detección con muy buenos resultados como se extrae de \cite{Ozdemir2014}. En \cite[p.6]{Musci2020} se llega a la conclusión de que el uso de la información de la aceleración únicamente es una fuente de información suficientemente fiable para obtener métricas de detección satisfactorias usando una red neuronal recurrente.

Usando inteligencia artificial, Shi \cite{Shi2020} describe un método basado en acelerómetro triaxial llevado en la cintura para predecir caidas, tratando una caida como una actividad humana más y usando métodos similares a los usados para la predicción de actividad humana (CNN). Casilari en \cite[p.17]{Casilari2020} usa una red de 4 capas convolucionales para el mismo fin, y compara el rendimiento sobre multitud de datasets obteniendo que si bien se puede optimizar el rendimiento para un conjunto en concreto logrando resultados de precisión y especificidad del orden del 100\%, es muy costoso generar un modelo que generalice a todos los datasets. A su vez analiza el impacto de otros parámetros como el tamaño de la ventana temporal \cite[p.16]{Casilari2020}, considerando que a partir de 5 segundos no hay ningún beneficio extra en aumentar el tamaño de la ventana. En \cite[p.59]{Hassan2019} usan una ventana de 1s consiguiendo mejorar los clasificadores existentes. Resultado que coincide con \cite[p.2]{Liu2018} que deslimita la duración de una caída entre los 0,4 y 0,8 segundos, demostrando que una frecuencia de muestreo de 21,3Hz es suficiente cuando se utilizan modelos de aprendizaje automático. Madrano \cite{tfall} usa K-NearestNeighbours y SVM para detectar actividad y varios tipos de caídas, mostrando buenos resultados con SVM que además parece ser capaz de distinguir caídas para las que no ha sido entrenado.

Finalmente, en \cite{Anita2020} tenemos un resumen con los últimos avances y resultados. Introduce otras fuentes de información como es el riesgo biológico, o predisposicion a la caída debido a la edad y otros factores de deterioro de la salud.

Varios estudios \cite{Luque2014,Aziz2017,Aziz2017b} llegan a conclusiones similares respecto a la alta variabilidad de los resutlados según el conjunto de datos de entrenamiento usado, especialmente en los métodos basados en cotas. Sin embargo en \cite[p.9]{Aziz2017b} confirma el resultado de \cite[tfall] sobre la mayor capacidad de generalización de los modelos basados en SVM. A la ver que introduce  encuentra que SVM llega a generalizar incluso con tipos de caídas para las que no había sido entrenado. En la segunda obra analiza en más detalle la detección con SVM usando caídas reales y sugiere usar una combinación de métodos basados en cotas junto con técnicas de aprendizaje automático para obtener mejores estimadores.

\subsection{Modelos basados en eventos o híbridos}\label{sa_modelos_hybridos}

Putra \cite{Putra2017} y Lim \cite{Lim2014} definen modelos híbridos que ofrecen una alternativa a los complejos y computacionalmente costosos modelos de aprendizaje automático y a los simples pero poco precisos modelos analíticos aunando las ventajas de ambos. En sus trabajos usan una etapa de detección basada en las propiedades analíticas de una caída y una posterior etapa de clasificación o decisión basada en modelos más complejos obteniendo "Mejores resultados que con el método de cotas simple (...) y una fuerte reducción del coste computacional respecto al uso del modelo HMM únicamente"\cite[p.5]{Lim2014}.

\section{Predicción de series temporales}

El uso de redes neuronales recurrentes para la predicción de series temporales es ampliamente respondido hoy en dia \todo{citar estudios}. Basaremos la etapa de clasificación en la capacidad de predecir episodios conocidos de este tipo de redes.

\section{GRU vs LSTM para predicción de series}\label{sa_rnn}

Respecto al uso de LSTM para detectar anomalías en series temporales, Wang \cite{Wang2020} usa LSTM para identificar anomalías en la señal de un motor (aunque el usa el error de recostrucción de la descomposición y recomposición wavelet de la señal como entrada a una triple red LSTM, nuestro enfoque es el contrario: usar LSTM a modo de transformada wavelet y luego comparar el error de recomposición).

in\cite{Qin2019} estudia el comportamiento de varias redes recurrentes para la predicción de la saturación de oxígeno en el agua y obtiene que las GRU son las que mejores predicciones (menos error) obtienen (Sobre LSTM e incluso RNN bidireccional). Kofi \cite{Koffi2020} compara LSTM y GRU para predecir mercado de valores con topologías muy variadas (número de celdas, de capas, stateless o no) y encuentra que GRU tiene mejor tasa de aciertos teniendo en cuenta el coste computacional (y muchas veces sin tenerlo) y que no siempre tener dos capas de RNN da mejores resultados.

Alicado al problema de la predicción de la actividad humana, Li\cite{Li2019} usa redes con varias capas LSTM bidireccionales usando los datos obtenidos por un acelerómetro y un radar con un dispositivo de captura en la muñeca mientras consigue resultados comparables a las mejores técnicas de clasificación existentes.

\section{Pruning y técnicas para reducir complejidad de modelos}\label{sa_optimizacion}

A pesar de la creciente capacidad de cálculo de los dispositivos llevables, será necesario optimizar el rendimiento del modelo con el fin de conseguir la mayor capacidad de predicción por Hz del sistema. Para ello dispondremos de dos técnicas: \textit{Pruning} y \textit{Cuantificación}.

\subsection{Pruning}
Un modelo de redes neuronales se puede entender como una matriz de pesos que indican la contribción de cada nodo o neurona al resultado final. Es normal que en esa red haya nodos que aporten más información que otros. Este efecto no es necesariamente negativo, la regularización o normalización L1 busca precisamente este efecto para reducir el sobreajuste de la red a los datos de entrenamiento.

Esta diferencia de aportación nos permite realizar una compresión del modelo. Si aceptamos sufrir unas ciertas pérdidas en la capacidad predictiva del mismo, podemos eliminar los nodos de menor peso reduciendo el tamaño de la red y su consumo de memoria. Esta reducción permite además acelerar el modelo y adaptarlo al uso en sistemas embebidos.\todo{Buscar bibliografía formal para: https://www.machinecurve.com/index.php/2020/09/23/tensorflow-model-optimization-an-introduction-to-pruning/}

\todo{Este artículo cita referencias y es ligeramente más técnico.
https://www.machinecurve.com/index.php/2020/09/29/tensorflow-pruning-schedules-constantsparsity-and-polynomialdecay/}

Una de las técnicas más sencillas para realizar esta eliminación de nodos consiste en definir una aportación mínima objetivo y comparar la magnitud de la aportación individual al resultado final, eliminando aquellos que no alcanzan el nivel $\lambda$ deseado
\[
\hat{w_i} = \left\{ \begin{matrix} w_i & :\mbox{si} |w_i|>\lambda\\
  0 & :\mbox{si} |w_i|\leq\lambda\end{matrix} \right.
\]

Esta compresión se puede hacer sobre un modelo ya entrenado (sendo recomendable realizar un nuevo proceso de entrenamiento para balancear los pesos de los nodos existentes y reducir el error introducido) o realizarlo durante el entrenamiento como si de una regularización más se tratara.

En el caso de TensorFlow, el entorno usado para este proyecto, se permite realizar esta regularización durante el entrenamiento de dos formas:

\begin{itemize}
\item Eliminando nodos de forma lineal, o a tasa constante
\item Eliminando nodos de forma polinomial, o a tasa creciente
\end{itemize}

\subsection{Cuantificación}
\warn{citas necesarias}
Entendemos por cuantificación al proceso de discretizar un grupo de valores. En este caso hace referencia precisamente al descenso en la precisión numérica usada para representar los pesos de nodos y valores de entrada y salida de una red neuronal.

La cuantificación de los valores de entrada y salida a la red consiste en reducir el peso de estos valores. Normalmente se normaliza la entrada y se convierte en valores de tipo entero. Tras el paso por la red, a la salida se aplicac la operación inversa para escalar la salida al rango de valores esperado.

Por su parte la cuantificación de la red neuronal realiza una operación similar con los pesos de los enlaces de las neuronas. Reduce la precisión de las representaciones de estos valores consiguiendo un ahorro en recursos y una mejora en tiempo de cálculo al eliminar el requisito de usar unidades de coma flotante en sistemas embebidos.


\end{document}
